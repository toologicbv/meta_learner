{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/home/jogi/git/repository/meta_learner\")\n",
    "if \"/home/jogi/.local/lib/python2.7/site-packages\" in sys.path:\n",
    "    sys.path.remove(\"/home/jogi/.local/lib/python2.7/site-packages\")\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "\n",
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "import itertools\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn import init\n",
    "\n",
    "import numpy as np\n",
    "import dill\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "from utils.experiment import Experiment\n",
    "from utils.common import get_model, create_def_argparser, create_logger, softmax\n",
    "from utils.plots import loss_plot, param_error_plot, plot_qt_probs, plot_dist_optimization_steps\n",
    "from utils.plots import plot_actsb_qts, plot_image_map_data, plot_image_map_losses\n",
    "from utils.plots import plot_loss_over_tsteps\n",
    "from utils.probs import TimeStepsDist, ConditionalTimeStepDist\n",
    "from utils.config import config\n",
    "from val_optimizer import validate_optimizer\n",
    "from utils.regression import RegressionFunction, L2LQuadratic, RegressionWithStudentT\n",
    "from utils.helper import tensor_and, tensor_any\n",
    "from utils.batch_handler import ACTBatchHandler\n",
    "from utils.epoch import Epoch\n",
    "from models.rnn_optimizer import MetaLearner, AdaptiveMetaLearnerV1, AdaptiveMetaLearnerV2\n",
    "from models.sb_act_optimizer import StickBreakingACTBaseModel\n",
    "\n",
    "from utils.regression import RegressionFunction, L2LQuadratic, neg_log_likelihood_loss, RosenBrock\n",
    "from utils.regression import RegressionWithStudentT\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exper = Experiment.load(\"run_20170811_15_35_39_act_sbV1_2ep_nu0.1_lr5e05\", do_log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exper.save(file_name=\"something_new.dll\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expers_to_load = [# Meta V1 model regressionT\n",
    "                  # Stick-breaking V1 model\n",
    "                  (False, \"run_20170724_22_55_12_actV2_70ep_32ops_lr5e05_adam\"), # nu=0.1\n",
    "                  (True, \"run_20170811_14_04_39_act_sbV1_45ep_nu0.3_lr5e05\"), # nu=0.3\n",
    "                  (False, \"run_20170724_17_46_16_actV2_70ep_32ops_lr5e05_adam\"), # nu=0.6\n",
    "                  (True, \"run_20170810_17_16_01_act_sbV1_50ep_nu0.9_lr5e05\"), # 0.9\n",
    "                  (True, \"run_20170810_17_43_18_act_sbV1_50ep_nu0.95_lr5e05\")] # nu=0.95\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "without_models = True\n",
    "\n",
    "experiments = []\n",
    "models = []\n",
    "new_experiments = []\n",
    "explogger = None\n",
    "m = 0\n",
    "for e, exp_path in enumerate(expers_to_load):\n",
    "    if exp_path[0]:\n",
    "        print(\"Try... {}\".format(exp_path[1]))\n",
    "        exp = get_experiment(exp_path[1])\n",
    "        if \"act\" in exp.args.model:\n",
    "            print(\"{} Loading model {} (q-prob {:.2f}) / {}\".format(m, exp.args.model, \n",
    "                                                                    exp.config.ptT_shape_param,\n",
    "                                                                    exp.args.log_dir))\n",
    "        else:\n",
    "            print(\"{} Loading model {} / {}\".format(m, exp.args.model, exp.args.log_dir))\n",
    "        \n",
    "        experiments.append(exp)\n",
    "        if explogger is None:\n",
    "            explogger = create_logger(exp, file_handler=False)\n",
    "        m += 1\n",
    "        if not without_models:\n",
    "            models.append(get_model(exp, exp.args.x_dim, retrain=True, logger=explogger))\n",
    "        new_experiments.append(Experiment(exp.args, exp.config))\n",
    "        new_experiments[-1].output_dir = experiments[-1].output_dir\n",
    "        new_experiments[-1].reset_val_stats()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del new_experiments\n",
    "new_experiments = []\n",
    "\n",
    "for exper in expers_to_load:\n",
    "    if exper[0]:\n",
    "        new_experiments.append(get_experiment(path_to_exp=exper[1] + \"/\" + \"exp_statistics_test10000.dll\",\n",
    "                                              full_path=True))\n",
    "print(\"Ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"data/test_regression_T_10000_10_1.0_10.dll\", 'rb') as f:\n",
    "     test_funcs = dill.load(f)\n",
    "print(\"Ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# new_exp_only = [new_experiments[0], new_experiments[4], new_experiments[8], new_experiments[12]] \n",
    "best_val_runs, lowest_value = plot_loss_over_tsteps(new_experiments, do_show=True, \n",
    "                                              do_save=False, \n",
    "                                              plot_best=False,\n",
    "                                              fig_name=\"10regT_actsb\", \n",
    "                                              loss_type=\"loss\",\n",
    "                                              min_step=0,\n",
    "                                              max_step=200,\n",
    "                                              sort_exper=\"10d-regression (student-t)\",\n",
    "                                              log_scale=False,\n",
    "                                              with_stddev=False,\n",
    "                                              runID=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss_plot(experiments[1], loss_type=\"opt_loss\", save=True, show=True, \n",
    "          log_scale=False, validation=True, only_val=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# exp_error_curves = [experiments[0],  experiments[3]]\n",
    "for exp, mdl in zip(experiments, models):\n",
    "    print(mdl.name)\n",
    "    loss_plot(exp, loss_type=\"loss\", save=False, validation=True, show=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# eval_new_val_expers = [new_experiments[0], new_experiments[3]] #, new_experiments[5]]\n",
    "\n",
    "best_val_runs, lowest_value = plot_val_result(new_experiments, \n",
    "                                              do_show=True, \n",
    "                                              do_save=True, \n",
    "                                              plot_best=False,\n",
    "                                              loss_type=\"loss\",\n",
    "                                              fig_name=\"expv5_val_results_1000_loss_10ops\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# eval_expers = new_exp_only = [experiments[0], experiments[1], experiments[2]]\n",
    "plot_parm_loss_steps(experiments, num_of_plots=4, do_show=True, \n",
    "                     do_save=False, loss_type=\"loss\", log_scale=False, max_step=20,\n",
    "                    fig_name=\"metaV2_val_loss_during_training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_funcs = RegressionFunction(n_funcs=15000, n_samples=10, stddev=1.0, \n",
    "                             x_dim=10, use_cuda=True)\n",
    "with open(\"data/val_funcs_15000_10_1.0_10.dll\", 'wb') as f:\n",
    "     dill.dump(val_funcs, f)\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Create some new validation functions\n",
    "\"\"\"\n",
    "num_of_val_funcs = 20000\n",
    "            val_funcs = L2LQuadratic(batch_size=num_of_val_funcs, num_dims=10, stddev=0.01, use_cuda=True)\n",
    "print(\"Ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"data/val_funcs_20000_10_1.0_10.dll\", 'rb') as f:\n",
    "    val_funcs = dill.load(f)\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_funcs = RegressionWithStudentT(n_funcs=10000, n_samples=10, x_dim=10, scale_p=1., shape_p=1, use_cuda=True)\n",
    "with open(\"data/test_regression_T_10000_10_1.0_10.dll\", 'wb') as f:\n",
    "     dill.dump(test_funcs, f)\n",
    "print(\"Ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "exp_idx = 1\n",
    "model = models[exp_idx]\n",
    "\n",
    "max_steps = 1000\n",
    "# new_experiments[exp_idx].model_path\n",
    "\n",
    "new_experiments[exp_idx].epoch = 400\n",
    "new_experiments[exp_idx].config.max_val_opt_steps = max_steps\n",
    "new_experiments[exp_idx].config.T = max_steps\n",
    "new_experiments[exp_idx].meta_logger = explogger\n",
    "\n",
    "epoch_obj = Epoch(new_experiments[exp_idx])\n",
    "epoch_obj.start()\n",
    "    \n",
    "new_experiments[exp_idx].eval(epoch_obj, model, functions=test_funcs, save_run=None, save_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(len(new_experiments))\n",
    "exp_idx = 1\n",
    "max_steps = 1000\n",
    "new_experiments[exp_idx].epoch = 400\n",
    "new_experiments[exp_idx].config.max_val_opt_steps = max_steps\n",
    "new_experiments[exp_idx].config.T = max_steps\n",
    "new_experiments[exp_idx].config.qt_threshold = 0.95\n",
    "new_experiments[exp_idx].reset_val_stats()\n",
    "# the same object for the validation data\n",
    "model = models[exp_idx]\n",
    "model.opt_step_hist_val = np.zeros(new_experiments[exp_idx].config.max_val_opt_steps)\n",
    "model.qt_hist_val = OrderedDict([(i, np.zeros(i)) \n",
    "                                 for i in np.arange(1, new_experiments[exp_idx].config.max_val_opt_steps + 1)])\n",
    "print(\"Validating model {} with q-prob {:.3f}\".format(model.name, experiments[exp_idx].config.ptT_shape_param))\n",
    "\n",
    "if \"act\" in model.name:\n",
    "    model.init_qt_statistics(new_experiments[exp_idx].config)\n",
    "\n",
    "validate_optimizer(model, new_experiments[exp_idx], explogger, val_set=test_funcs, \n",
    "                   max_steps=max_steps, verbose=False, plot_func=False, show_plot=False, save_plot=False,\n",
    "                   num_of_plots=5, save_model=False, save_qt_prob_funcs=False, save_run=\"test10000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_qt_probs(new_experiments[2], data_set=\"val\", save=True, show=True, \n",
    "              plot_prior=False, height=20, width=20, add_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils.plots import create_exper_label\n",
    "num_of_plots = 13\n",
    "T0 = 23\n",
    "fig = plt.figure(figsize=(8, 25))\n",
    "\n",
    "for i in range(1, num_of_plots+1):\n",
    "    T = T0+i\n",
    "    index = np.arange(1, T+1).astype(int)\n",
    "    qt = exper.val_stats[\"qt_hist\"][30][T]\n",
    "    ax1 = plt.subplot(num_of_plots, 1, i)\n",
    "    plt.bar(index, qt, 0.3, label=\"q(t|{})\".format(T))\n",
    "    ax1.legend(loc=\"best\")\n",
    "    \n",
    "fig_name = \"_\" + \"val\" + \"_\" + create_exper_label(exper)\n",
    "fig_name = os.path.join(exper.output_dir, config.qt_dist_prefix + fig_name + \".png\")\n",
    "plt.savefig(fig_name, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_qt_mode_hist(new_experiments[1], do_save=False, do_show=True, add_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_yt(W, x):\n",
    "    return torch.transpose(torch.mm(W ,x.unsqueeze(1)), 1,0)\n",
    "\n",
    "def compute_params(W, y, cuda=False):\n",
    "    \n",
    "    A_plus = np.linalg.pinv(W.data.cpu().numpy())\n",
    "    y = y.data.cpu().numpy()\n",
    "    params = np.squeeze(np.dot(A_plus, y))\n",
    "    params = Variable(torch.from_numpy(params).float().unsqueeze(0))\n",
    "    if cuda:\n",
    "        params = params.cuda()\n",
    "    return params\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_qt_detailed_stats(new_experiments[0], test_funcs, do_save=True, do_show=True, threshold=0.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " # \n",
    "plot_kl_div_parts(new_experiments[1], save=False, show=True, final_terms=False, log_qt=True, plot_prior=True,\n",
    "                 fig_name=\"kl_parts_without_tanh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "s = 0.05   # Try s=1, 0.25, 0.1, or 0.05\n",
    "X = np.arange(-1.2, 4+s, s)   #Could use linspace instead if dividing\n",
    "Y = np.arange(10, 13+s, s)   #evenly instead of stepping...\n",
    "    \n",
    "#Create the mesh grid(s) for all X/Y combos.\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "\n",
    "#Rosenbrock function w/ two parameters using numpy Arrays\n",
    "Z = (3.5-X)**2 + 100.*(Y-X*X)**2\n",
    "\n",
    "surf = ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap=cm.coolwarm,\n",
    "         linewidth=0, antialiased=False)  #Try coolwarm vs jet\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "# ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "# ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n",
    "\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "\n",
    "#Displays the figure, handles user interface, returns when user closes window\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rosenbrockfunction = lambda x,y: (3.5-x)**2+100*(y-x**2)**2\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "n = 100 # number of discretization points along the x-axis\n",
    "m = 100 # number of discretization points along the x-axis\n",
    "a=-2.5; b=4 # extreme points in the x-axis\n",
    "c=8; d=10 # extreme points in the y-axis\n",
    "\n",
    "X,Y = np.meshgrid(np.linspace(a,b,n), np.linspace(c,d,m))\n",
    "\n",
    "Z = rosenbrockfunction(X,Y)\n",
    "\n",
    "plt.contour(X,Y,Z,np.logspace(-0.5,3.5,20,base=10),cmap='gray')\n",
    "plt.title(r'$\\textrm{Rosenbrock Function: } f(x,y)=(1-x)^2+100(y-x^2)^2$')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "from math import exp\n",
    "\n",
    "\n",
    "def rbf_kernel(x1, x2, variance = 1):\n",
    "    return exp(-1 * ((x1-x2) ** 2) / (2*variance))\n",
    "\n",
    "def gram_matrix(xs):\n",
    "    return [[rbf_kernel(x1,x2) for x2 in xs] for x1 in xs]\n",
    "\n",
    "xs = np.arange(-1, 1, 0.01)\n",
    "mean = [0 for x in xs]\n",
    "gram = gram_matrix(xs)\n",
    "\n",
    "plt_vals = []\n",
    "for i in range(0, 5):\n",
    "    ys = np.random.multivariate_normal(mean, gram)\n",
    "    plt_vals.extend([xs, ys, \"k\"])\n",
    "plt.plot(*plt_vals)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expers_to_load = [# Meta V3 model regression\n",
    "                  (True, \"run_20170713_17_03_57_metaV1_10ep_100ops_retrain_lr1e04_adam\"), # weights=1\n",
    "                  (True, \"run_20170713_16_12_22_metaV3.1_10ep_100ops_lr1e04_adam\"),  # nu=0.3, 10 epochs\n",
    "                  (True, \"run_20170714_10_28_31_metaV3.1_10ep_100ops_lr1e04_adam\"), # nu=0.5, 10 epochs\n",
    "                  (True, \"run_20170713_17_16_28_metaV3.1_16ep_100ops_lr1e04_adam\"), # nu=0.7, 14 epochs\n",
    "                  (True, \"run_20170713_17_15_05_metaV3.1_16ep_100ops_lr1e04_adam\"), # nu=0.9, 16 epochs\n",
    "                  (True, \"run_20170713_16_39_30_metaV3.2_10ep_100ops_retrain_lr1e04_adam\")] # uniform, 12 epochs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
